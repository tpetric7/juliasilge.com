---
title: "Text predictors for #TidyTuesday chocolate ratings"
author: Julia Silge
date: '2022-01-21'
slug: chocolate-ratings
categories:
  - rstats
  - tidymodels
tags:
  - rstats
  - tidymodels
subtitle: ''
summary: "Get started with feature engineering for text data, transforming text to be used in machine learning algorithms."
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: true
projects: []
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, 
                      echo = TRUE, dpi = 300, cache.lazy = FALSE,
                      tidy = "styler", fig.width = 8, fig.height = 5)
library(scales)
library(tidyverse)
library(silgelib)
theme_set(theme_plex())
update_geom_defaults("rect", list(fill = "midnightblue", alpha = 0.8))
```


This is the latest in my series of [screencasts](https://juliasilge.com/category/tidymodels/) demonstrating how to use the [tidymodels](https://www.tidymodels.org/) packages, from just getting started to tuning more complex models. Today's screencast is a good one for folks newer to tidymodels and focuses on predicting with text data, using this week's [`#TidyTuesday` dataset](https://github.com/rfordatascience/tidytuesday) on chocolate ratings. `r emo::ji("chocolate")`

```{r, echo=FALSE}
blogdown::shortcode("youtube", "w-lF65hKtrQ")
```

</br>

Here is the code I used in the video, for those who prefer reading instead of or in addition to video.

## Explore data

Our modeling goal is to predict ratings for [chocolate](https://github.com/rfordatascience/tidytuesday/blob/master/data/2022/2022-01-18/readme.md) based on the main characteristics as described by the raters. It's not likely that we can build a high performing model using only these short text descriptions but we can use this dataset to demonstrate how to approach feature engineering for text. How are the ratings distributed?

```{r}
library(tidyverse)

url <- "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-18/chocolate.csv"
chocolate <- read_csv(url) 

chocolate %>%
  ggplot(aes(rating)) +
  geom_histogram(bins = 15)
```

What are the most common words used to describe the most memorable characteristics of each chocolate sample?

```{r}
library(tidytext)

tidy_chocolate <-
  chocolate %>%
  unnest_tokens(word, most_memorable_characteristics)

tidy_chocolate %>%
  count(word, sort = TRUE)
```

What is the mean rating for these words?

```{r, fig.width=9.5, fig.height=6}
tidy_chocolate %>%
  group_by(word) %>%
  summarise(n = n(),
            rating = mean(rating)) %>%
  ggplot(aes(n, rating)) +
  geom_hline(yintercept = mean(chocolate$rating), lty = 2, 
             color = "gray50", size = 1.5) +
  geom_jitter(color = "midnightblue", alpha = 0.7) +
  geom_text(aes(label = word), check_overlap = TRUE, family = "IBMPlexSans",
            vjust = "top", hjust = "left") +
  scale_x_log10()
```

Complex, balanced chocolate is good, but burnt, pastey chocolate is bad. 

## Build models

Let’s start our modeling by setting up our "data budget." We'll stratify by our outcome `rating`.

```{r}
library(tidymodels)

set.seed(123)
choco_split <- initial_split(chocolate, strata = rating)
choco_train <- training(choco_split)
choco_test <- testing(choco_split)

set.seed(234)
choco_folds <- vfold_cv(choco_train, strata = rating)
choco_folds
```

Next, let’s set up our feature engineering. We will need to transform our text data into features useful for our model by tokenizing and computing (in this case) tf-idf.

```{r}
library(textrecipes)

choco_rec <- 
  recipe(rating ~ most_memorable_characteristics, data = choco_train) %>%
  step_tokenize(most_memorable_characteristics) %>%
  step_tokenfilter(most_memorable_characteristics, max_tokens = 100) %>%
  step_tfidf(most_memorable_characteristics)

## just to check this works
prep(choco_rec) %>% bake(new_data = NULL)
```

Now let's create two model specifications to compare. Random forests are not known for performing well with natural language predictors, but this dataset involves very short text descriptions so let's give it a try. Support vector machines _do_ tend to work well with text data so let's include that one too.

```{r}
rf_spec <- 
  rand_forest(trees = 500) %>%
  set_mode("regression")

rf_spec

svm_spec <-
  svm_linear() %>%
  set_mode("regression")

svm_spec
```

Now it's time to put the preprocessing and model together in a `workflow()`. The SVM requires the predictors to [all be on the same scale](https://www.tmwr.org/pre-proc-table.html), but all our predictors are now tf-idf values so we should be pretty much fine.

```{r}
svm_wf <- workflow(choco_rec, svm_spec)
rf_wf <- workflow(choco_rec, rf_spec)
```


## Evaluate models

These workflows have no tuning parameters so we can evaluate them as they are. (Random forest models _can_ be tuned but they tend to work fine with the defaults as long as you have enough trees.)

```{r}
doParallel::registerDoParallel()
contrl_preds <- control_resamples(save_pred = TRUE)

svm_rs <- fit_resamples(
  svm_wf,
  resamples = choco_folds,
  control = contrl_preds
)

ranger_rs <- fit_resamples(
  rf_wf,
  resamples = choco_folds,
  control = contrl_preds
)
```

How did these two models compare?

```{r}
collect_metrics(svm_rs)
collect_metrics(ranger_rs)
```

We can visualize these results by comparing the predicted rating with the true rating:

```{r, fig.width=10}
bind_rows(
  collect_predictions(svm_rs) %>%
    mutate(mod = "SVM"),
  collect_predictions(ranger_rs) %>%
    mutate(mod = "ranger")
) %>%
  ggplot(aes(rating, .pred, color = id)) +
  geom_abline(lty = 2, color = "gray50", size = 1.2) +
  geom_jitter(width = 0.5, alpha = 0.5) +
  facet_wrap(vars(mod)) +
  coord_fixed()
```

These models are not great but they perform pretty similarly, so perhaps we would choose the faster-to-train, linear SVM model. The function `last_fit()` *fits* one final time on the training data and *evaluates* on the testing data. This is the first time we have used the testing data.

```{r}
final_fitted <- last_fit(svm_wf, choco_split)
collect_metrics(final_fitted)  ## metrics evaluated on the *testing* data
```

This object contains a fitted workflow that we can use for prediction.

```{r}
final_wf <- extract_workflow(final_fitted)
predict(final_wf, choco_test[55,])
```

You can save this fitted `final_wf` object to use later with new data, for example with `readr::write_rds()`.

One nice aspect of using a linear model is that we can directly inspect the coefficients for each term. Which words are more associated with high ratings vs. low ratings?

```{r}
extract_workflow(final_fitted) %>%
  tidy() %>%
  filter(term != "Bias") %>%
  group_by(estimate > 0) %>%
  slice_max(abs(estimate), n = 10) %>%
  ungroup() %>%
  mutate(term = str_remove(term, "tfidf_most_memorable_characteristics_")) %>%
  ggplot(aes(estimate, fct_reorder(term, estimate), fill = estimate > 0)) +
  geom_col(alpha = 0.8) +
  scale_fill_discrete(labels = c("low ratings", "high ratings")) +
  labs(y = NULL, fill = "More from...")
```

I know I personally would prefer creamy, rich chocolate to bitter, chalky chocolate!
