---
title: "Predict the magnitude of #TidyTuesday tornadoes with effect encoding and xgboost"
author: Julia Silge
date: '2023-05-20'
format: hugo
slug: tornadoes
categories:
  - rstats
  - tidymodels
tags:
  - rstats
  - tidymodels
summary: "How well can we predict the magnitude of tornadoes in the US? Let's use xgboost along with effect encoding to fit our model."
---

```{r setup}
#| include: false
library(knitr)
knitr::opts_chunk$set(cache = TRUE, cache.lazy = FALSE, warning = FALSE, 
                      message = FALSE, echo = TRUE, dpi = 180,
                      fig.width = 7, fig.height = 5)
library(tidyverse)
library(silgelib)
theme_set(theme_light_plex())
update_geom_defaults("rect", list(fill = "midnightblue", alpha = 0.8))
update_geom_defaults("line", list(color = "midnightblue", alpha = 0.8))

library(wikipediapreview)
wp_init()

## if you don't have fancy fonts like IBM Plex installed, run
## theme_set(theme_minimal())
```

This is the latest in my series of [screencasts](https://www.youtube.com/juliasilge)! This screencast focuses on how to use tidymodels for feature engineering such as dealing with dates and effect encoding, using this week's [`#TidyTuesday` dataset](https://github.com/rfordatascience/tidytuesday) on tornadoes in the United States. üå™Ô∏è

```{r}
#| echo: false
blogdown::shortcode("youtube", "S3QBlcNFKAI")
```

</br>

Here is the code I used in the video, for those who prefer reading instead of or in addition to video.

## Explore data

Our modeling goal in this case is to predict the [magnitude of tornadoes](https://en.wikipedia.org/wiki/Tornado_intensity) based on [tornado characteristics](https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-05-16/) like when and where it occurred. Let's start by reading in the data:

```{r}
library(tidyverse)

tornadoes <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-16/tornados.csv')

glimpse(tornadoes)
```

Before we can build a model, we'll have to decide how to try to formulate our prediction question. How is the outcome `mag` distributed?

```{r}
tornadoes |> 
  ggplot(aes(mag, fill = fc)) +
  geom_bar(position = position_dodge(preserve = "single")) +
  scale_y_log10() +
  labs(fill = "Estimated?")
```

We could try out excluding the tornadoes with estimated magnitudes, but a larger challenge is that the outcome we want to model is sort of like a count or integer, has just a ton of zeroes, can't be negative, and doesn't extend to very high values. I tend to consider these kinds of options in a situation like this:

- **Classification with multiple classes**: This isn't great because the "classes" are in a sequence, and classification metrics can't really tell us how wrong we are in a useful way.
- **Ordered outcome model, like `MASS::polr()`**: This is definitely a good fit for our outcome, but this kind of model is linear and when we have a big dataset like this including complex interactions, a linear model often leaves a lot of possible model performance on the table.
- **Zero-inflated Poisson regression**: We could treat the outcome as a count with lots of extra zeroes, but again, the implementations I am familiar with are linear.
- **Just pretend it is continuous**: What happens if we just treat this outcome as if it were a continuous numeric value? Much like with [my screencast last week](https://juliasilge.com/blog/childcare-costs/), this dataset has lots of variables in a big rectangular dataset, many of which are highly correlated with each other, so it's at the sweet spot for xgboost. What happens if we treat this as a regression problem and use xgboost?

Do different states in the US have more or less extreme tornadoes?

```{r}
tornadoes |> 
  group_by(st) |> 
  summarise(mag = mean(mag, na.rm = TRUE), n = n()) |> 
  arrange(-mag)
```

If we want to use this as a predictor, we likely want to think about how to handle the high cardinality of this feature. If we create dummy or indicator variables, we'll have ~50 new columns. Instead, we can use effect or likelihood encodings and keep this as _one_ column.

How is the magnitude of the tornado related to the number of injuries?

```{r}
tornadoes |> 
  filter(!is.na(mag)) |> 
  mutate(mag = factor(mag)) |> 
  ggplot(aes(mag, inj, fill = mag)) +
  geom_boxplot(alpha = 0.4, show.legend = FALSE) +
  scale_y_continuous(trans = scales::pseudo_log_trans(base = 10))
```

This looks like another power law; there are dramatic increases in the number of people injured as magnitude increases.

## Build a model

We can start by loading the tidymodels metapackage, splitting our data into training and testing sets, and creating cross-validation resamples. Think about this stage as _spending your data budget_. Let's also remove tornadoes without a `mag` measurement (we could also remove the estimated magnitudes here, if we wanted). 

```{r}
library(tidymodels)

set.seed(123)
tornado_split <- tornadoes |> 
  filter(!is.na(mag)) |> 
  initial_split(strata = mag)

tornado_train <- training(tornado_split)
tornado_test <- testing(tornado_split)

set.seed(234)
tornado_folds <- vfold_cv(tornado_train, strata = mag)
tornado_folds
```

Next, let‚Äôs create our feature engineering recipe, handling the high cardinality `st` variable using a likelihood or effect encoding. The way that this works is that we train a little mini model with only `st` and our outcome `mag`, and replace the original categorical variable with a single numeric column that measures its effect; the coefficients from the mini model are used to compute this new numeric column. Let's also use `date` to create indicator or dummy variables for month, and a numeric predictor for year.

```{r}
library(embed)

tornado_rec <- 
  recipe(mag ~ date + st + inj + fat + len + wid, data = tornado_train) |> 
  step_lencode_glm(st, outcome = vars(mag)) |> 
  step_date(date, features = c("month", "year"), keep_original_cols = FALSE) |> 
  step_dummy(all_nominal_predictors())

tornado_rec
```

How does this feature engineering recipe transform our training data?

```{r}
prep(tornado_rec) |> bake(new_data = NULL) |> glimpse()
```

We don't need to use `prep()` and `bake()` for our actual training or tuning, but they are useful for debugging feature engineering recipes.

Now let's create a tunable xgboost model specification and put it together with our feature engineering recipe in a `workflow()`. Notice that we have `set_mode("regression")`, even given the not-quite-continuous characteristics of our outcome.

```{r}
xgb_spec <-
  boost_tree(
    trees = tune(),
    min_n = tune(),
    mtry = tune(),
    learn_rate = 0.01
  ) |>
  set_engine("xgboost") |>
  set_mode("regression")

xgb_wf <- workflow(tornado_rec, xgb_spec)
```

I really like using racing methods with xgboost (so efficient!) so let‚Äôs use the [finetune](https://finetune.tidymodels.org/) package for tuning. Check out [this blog post](https://juliasilge.com/blog/uk-museums/) for another racing example.

```{r}
library(finetune)
doParallel::registerDoParallel()

set.seed(345)
xgb_rs <- tune_race_anova(
  xgb_wf,
  resamples = tornado_folds,
  grid = 15,
  control = control_race(verbose_elim = TRUE)
)

xgb_rs
```


## Evaluate and finalize model

How did our tuning with racing go?

```{r}
collect_metrics(xgb_rs)
plot_race(xgb_rs)
```

The racing method allowed us to drop the model hyperparameter configurations that weren‚Äôt performing very well. Let's use `last_fit()` to fit one final time to the training data and evaluate one final time on the testing data, with the numerically optimal result from `xgb_rs`.

```{r}
tornado_fit <- xgb_wf |>
  finalize_workflow(select_best(xgb_rs, "rmse")) |>
  last_fit(tornado_split)

tornado_fit
```

How did these predictions turn out? (Remember that these are predictions on the _testing_ data.)

```{r}
collect_predictions(tornado_fit) |> 
  ggplot(aes(.pred)) +
  geom_histogram()
```

This is not too bad, actually. 

```{r}
collect_predictions(tornado_fit) |> 
  mutate(mag = factor(mag)) |> 
  ggplot(aes(mag, .pred, fill = mag)) +
  geom_boxplot(alpha = 0.4, show.legend = FALSE)
```

We are still predicting too few minor, low-magnitude tornadoes with this model but the range of predictions is about right (no `mag = 40` tornadoes) and other than a lack of enough zeroes, the distribution looks pretty good. The lesson here is that sometimes a powerful model like xgboost that can learn complex interactions from large-ish, rectangular data does quite well, even when there are reasons it's not a perfect application.

What features are most important for this xgboost model?

```{r}
library(vip)

extract_workflow(tornado_fit) |>
  extract_fit_parsnip() |>
  vip(num_features = 10)
```

The number of injured people is an important predictor of magnitude (makes sense!), as are tornado length and width. The state predictor `st` ended up in the top 10, so I think it was worth it to use the effect encoding. Also, even accounting for characteristics like injuries/fatalities and tornado size, the month of the year still made it in there.

## Create a deployable model object

If you wanted to deploy this model, the next step is to create a deployable model object with [vetiver](https://vetiver.rstudio.com/):

```{r}
library(vetiver)
v <- extract_workflow(tornado_fit) |> 
  vetiver_model("tornado-xgb")
v
```

Like I mentioned in my last post, I am teaching a workshop at [posit::conf()](https://pos.it/conf) this coming September in Chicago on how to deploy and maintain models with vetiver. Join me if you are interested in learning more about this part of the modeling process, or [check out all the workshops](https://www.youtube.com/playlist?list=PL9HYL-VRX0oROlETlHRDAt0FzqnfkoG84) being organized for one that's a good fit for you!
